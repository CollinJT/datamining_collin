{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6883f50a",
   "metadata": {},
   "source": [
    "\n",
    "# W08 - Rule-Based Classification using PRISM Algorithm (from scratch)\n",
    "**Name:** Collin Joseph  \n",
    "**NIM:** 0706022310053  \n",
    "**Topic:** Rule-Based Classification using PRISM Algorithm  \n",
    "**Dataset:** Wine Dataset (from sklearn)\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Apply the PRISM rule-based classification algorithm.  \n",
    "- Interpret rules and explain model predictions in a human-understandable way.  \n",
    "- Evaluate model performance using confusion matrix and classification report.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1672b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================================================\n",
    "# W08 - PRISM Algorithm from Scratch - Collin Joseph\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Dataset\n",
    "# -----------------------------\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Series(wine.target, name='Y')\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Discretize Continuous Attributes (Low, Med, High)\n",
    "# -----------------------------\n",
    "def discretize_terciles(df, cols):\n",
    "    df_disc = df.copy()\n",
    "    for c in cols:\n",
    "        q = df[c].quantile([0, 1/3, 2/3, 1]).values\n",
    "        edges = np.unique(q)\n",
    "        if len(edges) < 4:\n",
    "            edges = np.linspace(df[c].min(), df[c].max(), 4)\n",
    "        df_disc[c + '_binned'] = pd.cut(df[c], bins=edges, labels=['Low','Med','High'], include_lowest=True)\n",
    "    return df_disc\n",
    "\n",
    "df_disc = discretize_terciles(df, wine.feature_names)\n",
    "binned_cols = [c + '_binned' for c in wine.feature_names]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Visualizations (EDA)\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8,4))\n",
    "for cls in sorted(df['Y'].unique()):\n",
    "    plt.hist(df[df['Y']==cls]['alcohol'], bins=12, alpha=0.6, label=f'class {cls}')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Alcohol by Class')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for cls in sorted(df['Y'].unique()):\n",
    "    sel = df[df['Y']==cls]\n",
    "    plt.scatter(sel['alcohol'], sel['color_intensity'], alpha=0.7, label=f'class {cls}')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Color Intensity')\n",
    "plt.title('Alcohol vs Color Intensity')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. PRISM Implementation from Scratch\n",
    "# -----------------------------\n",
    "class PrismFromScratch:\n",
    "    def __init__(self, df, target_col, feature_cols):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.rules = {}\n",
    "        \n",
    "    def _accuracy_of_condition(self, data, attr, val, positive_class):\n",
    "        subset = data[data[attr] == val]\n",
    "        if len(subset) == 0:\n",
    "            return 0, 0, 0.0\n",
    "        p = (subset[self.target_col] == positive_class).sum()\n",
    "        n = (subset[self.target_col] != positive_class).sum()\n",
    "        acc = p / (p + n) if (p + n) > 0 else 0.0\n",
    "        return int(p), int(n), float(acc)\n",
    "    \n",
    "    def learn_rules_for_class(self, positive_class):\n",
    "        data = self.df.copy()\n",
    "        rules_for_class = []\n",
    "        positives_remaining = data[data[self.target_col] == positive_class]\n",
    "        \n",
    "        while len(positives_remaining) > 0:\n",
    "            rule_conditions = {}\n",
    "            covered = data.copy()\n",
    "            while True:\n",
    "                best = None\n",
    "                best_metrics = (0,0,0.0)\n",
    "                for attr in self.feature_cols:\n",
    "                    if attr in rule_conditions:\n",
    "                        continue\n",
    "                    for val in data[attr].dropna().unique():\n",
    "                        p, n, acc = self._accuracy_of_condition(covered, attr, val, positive_class)\n",
    "                        if p == 0: continue\n",
    "                        if (acc > best_metrics[2]) or (acc == best_metrics[2] and p > best_metrics[0]):\n",
    "                            best = (attr, val)\n",
    "                            best_metrics = (p, n, acc)\n",
    "                if best is None: break\n",
    "                attr, val = best\n",
    "                rule_conditions[attr] = val\n",
    "                covered = covered[covered[attr] == val]\n",
    "                if all(covered[self.target_col] == positive_class): break\n",
    "                if len(covered) == 0:\n",
    "                    rule_conditions.pop(attr, None)\n",
    "                    break\n",
    "            if len(rule_conditions) == 0: break\n",
    "            covered_set = data.copy()\n",
    "            for a,v in rule_conditions.items():\n",
    "                covered_set = covered_set[covered_set[a] == v]\n",
    "            support = int((covered_set[self.target_col] == positive_class).sum())\n",
    "            coverage = len(covered_set)\n",
    "            rules_for_class.append({'conditions': rule_conditions.copy(), 'support': support, 'coverage': coverage})\n",
    "            covered_pos_idx = covered_set[(covered_set[self.target_col] == positive_class)].index\n",
    "            positives_remaining = positives_remaining.drop(index=covered_pos_idx, errors='ignore')\n",
    "            data = data.drop(index=covered_pos_idx, errors='ignore')\n",
    "            if (data[self.target_col] == positive_class).sum() == 0:\n",
    "                break\n",
    "        self.rules[positive_class] = rules_for_class\n",
    "        return rules_for_class\n",
    "    \n",
    "    def fit(self):\n",
    "        for c in sorted(self.df[self.target_col].unique()):\n",
    "            self.learn_rules_for_class(c)\n",
    "    \n",
    "    def predict_instance(self, x):\n",
    "        for c, rules in self.rules.items():\n",
    "            for r in rules:\n",
    "                conds = r['conditions']\n",
    "                if all(x[a] == v for a,v in conds.items() if a in x):\n",
    "                    return c\n",
    "        return int(self.df[self.target_col].mode()[0])\n",
    "    \n",
    "    def predict(self, X_df):\n",
    "        return np.array([self.predict_instance(row) for _, row in X_df.iterrows()])\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Train-Test Split & Model Training\n",
    "# -----------------------------\n",
    "X_binned = df_disc[binned_cols]\n",
    "y_col = df_disc['Y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binned, y_col, test_size=0.3, random_state=42, stratify=y_col)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "prism = PrismFromScratch(train_df, target_col='Y', feature_cols=binned_cols)\n",
    "prism.fit()\n",
    "\n",
    "print(\"=== Learned PRISM Rules ===\")\n",
    "for cls, rules in prism.rules.items():\n",
    "    print(f\"\\nClass {cls}:\")\n",
    "    for i, r in enumerate(rules, 1):\n",
    "        conds = \" AND \".join([f\"{a}={v}\" for a,v in r['conditions'].items()])\n",
    "        print(f\" Rule {i}: IF {conds} THEN class {cls} (support={r['support']}, coverage={r['coverage']})\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Evaluation\n",
    "# -----------------------------\n",
    "y_pred = prism.predict(X_test)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Predict New Data Points\n",
    "# -----------------------------\n",
    "new_data = pd.DataFrame({\n",
    "    'alcohol': [14.0, 14.0],\n",
    "    'malic_acid': [2.0, 2.0],\n",
    "    'ash': [2.3, 2.2],\n",
    "    'alcalinity_of_ash': [19.0, 11.0],\n",
    "    'magnesium': [95.0, 95.0],\n",
    "    'total_phenols': [2.2, 2.5],\n",
    "    'flavanoids': [0.14, 0.5],\n",
    "    'nonflavanoid_phenols': [0.14, 0.5],\n",
    "    'proanthocyanins': [1.6, 1.5],\n",
    "    'color_intensity': [7.0, 6.0],\n",
    "    'hue': [0.7, 0.6],\n",
    "    'od280/od315_of_diluted_wines': [3.2, 3.0],\n",
    "    'proline': [550.0, 1400.0]\n",
    "})\n",
    "new_disc = discretize_terciles(new_data, wine.feature_names)[0][binned_cols]\n",
    "preds = prism.predict(new_disc)\n",
    "print(\"\\nPredictions for New Data:\")\n",
    "print(preds)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
