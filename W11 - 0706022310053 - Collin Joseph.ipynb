{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525f0a5d",
   "metadata": {},
   "source": [
    "# W11 - KMeans and Hierarchical Clustering\n",
    "**Name:** Collin Joseph  \n",
    "**NIM:** 0706022310053\n",
    "\n",
    "**Dataset:** COVID-19 dataset (raw CSV)\n",
    "\n",
    "**Notebook purpose:** Complete solution for the W11 class assignment: data preprocessing, EDA, two clustering methods (KMeans & Hierarchical Agglomerative), evaluation (silhouette), cluster profiling, maps & barplots, recommendations, and model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e01bb",
   "metadata": {},
   "source": [
    "## How to run\n",
    "1. This notebook requires internet access to download the CSV from the raw GitHub URL. If you run it on Google Colab, make sure you enable internet (default).\n",
    "2. If you prefer, download the CSV manually and adjust the `DATA_URL` variable below to point to the local file path.\n",
    "3. Run all cells from top to bottom. All outputs (plots/tables) will be generated after execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Libraries & config ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dataset URL (raw GitHub link)\n",
    "DATA_URL = \"https://raw.githubusercontent.com/NathaliaMinoque/datasets/refs/heads/main/COVID-19%20Coronavirus%20(2).csv\"\n",
    "\n",
    "print('Notebook ready. Set DATA_URL =', DATA_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load dataset ---\n",
    "# If running locally and you already downloaded CSV, set local path: DATA_URL = '/path/to/COVID-19 (2).csv'\n",
    "df = pd.read_csv(DATA_URL)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6e5af",
   "metadata": {},
   "source": [
    "## 1) Data preprocessing\n",
    "- Inspect columns, datatypes, missing values\n",
    "- Convert numeric fields to appropriate dtypes\n",
    "- Create derived features: cases_per_million, deaths_per_million, CFR (if not present)\n",
    "- Handle missing values (imputation or drop if necessary)\n",
    "- Keep essential columns for clustering (e.g., population, cases_per_million, deaths_per_million, CFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preliminary cleaning & feature creation ---\n",
    "df.info()\n",
    "\n",
    "# Standardize column names (strip)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Try to convert numeric columns that may contain commas or strings\n",
    "def to_numeric_safe(col):\n",
    "    return pd.to_numeric(df[col].astype(str).str.replace(',','').str.replace('%',''), errors='coerce')\n",
    "\n",
    "candidates = ['Population','Total Cases','Total Deaths','Tot Cases//1M pop','Tot Deaths//1M pop','Death percentage']\n",
    "\n",
    "for c in candidates:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_numeric_safe(c)\n",
    "\n",
    "# Derived features if missing\n",
    "if 'Tot Cases//1M pop' not in df.columns and 'Total Cases' in df.columns and 'Population' in df.columns:\n",
    "    df['Tot Cases//1M pop'] = df['Total Cases'] / df['Population'] * 1e6\n",
    "if 'Tot Deaths//1M pop' not in df.columns and 'Total Deaths' in df.columns and 'Population' in df.columns:\n",
    "    df['Tot Deaths//1M pop'] = df['Total Deaths'] / df['Population'] * 1e6\n",
    "if 'Death percentage' not in df.columns and 'Total Cases' in df.columns and 'Total Deaths' in df.columns:\n",
    "    df['Death percentage'] = (df['Total Deaths'] / df['Total Cases']) * 100\n",
    "\n",
    "# Select columns for clustering\n",
    "cols_for_clustering = []\n",
    "for name in ['Population','Tot Cases//1M pop','Tot Deaths//1M pop','Death percentage']:\n",
    "    if name in df.columns:\n",
    "        cols_for_clustering.append(name)\n",
    "\n",
    "print('Using columns for clustering:', cols_for_clustering)\n",
    "df[cols_for_clustering].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f66ecf",
   "metadata": {},
   "source": [
    "## 2) Exploratory Data Analysis (EDA)\n",
    "- At least 2 meaningful visualizations are required, including a world map (choropleth by continent or cluster).\n",
    "- We'll produce:\n",
    "  1. Distribution plots of key features (cases per million, deaths per million, CFR)\n",
    "  2. Choropleth map by continent showing cases per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41430f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EDA plots ---\n",
    "plot_cols = [c for c in ['Tot Cases//1M pop','Tot Deaths//1M pop','Death percentage'] if c in df.columns]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for col in plot_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[col].dropna(), bins=60, kde=False)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choropleth by continent (mean cases per million)\n",
    "if 'Continent' in df.columns and 'Tot Cases//1M pop' in df.columns and 'ISO 3166-1 alpha-3 CODE' in df.columns:\n",
    "    agg = df.groupby('Continent', as_index=False)['Tot Cases//1M pop'].mean().rename(columns={'Tot Cases//1M pop':'Mean Cases per M'})\n",
    "    display(agg)\n",
    "    fig = px.choropleth(df, locations='ISO 3166-1 alpha-3 CODE', color='Tot Cases//1M pop',\n",
    "                        hover_name='Country', projection='natural earth',\n",
    "                        title='Cases per million by country (choropleth)')\n",
    "    fig.show()\n",
    "else:\n",
    "    print('Required columns for choropleth not found: Continent, Tot Cases//1M pop, ISO 3166-1 alpha-3 CODE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a418c",
   "metadata": {},
   "source": [
    "## 3) Encoding & Data Transformation\n",
    "- Scale numeric features using RobustScaler (robust to outliers)\n",
    "- Optionally, log-transform features with heavy skew prior to scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare data for clustering ---\n",
    "X = df[cols_for_clustering].copy()\n",
    "\n",
    "# Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "# Log transform highly skewed columns (add small constant)\n",
    "for c in X_imputed.columns:\n",
    "    if (X_imputed[c] > 0).sum() > 0:\n",
    "        X_imputed[c+'_log'] = np.log1p(X_imputed[c])\n",
    "\n",
    "# Choose log columns if created\n",
    "cols_final = [c for c in X_imputed.columns if c.endswith('_log')]\n",
    "if not cols_final:\n",
    "    cols_final = X_imputed.columns.tolist()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed[cols_final]), columns=cols_final, index=X.index)\n",
    "\n",
    "print('Final features used for clustering:', cols_final)\n",
    "X_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8383ebc3",
   "metadata": {},
   "source": [
    "## 4) KMeans: find best K using silhouette score\n",
    "We'll compute silhouette scores for K from 2 to 8 and pick the best K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb9893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Find best K ---\n",
    "sil_scores = {}\n",
    "for k in range(2,9):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labs = kmeans.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labs)\n",
    "    sil_scores[k] = sil\n",
    "sil_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette vs K\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(list(sil_scores.keys()), list(sil_scores.values()), marker='o')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score by K (KMeans)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit KMeans with best K (choose the K with max silhouette) ---\n",
    "best_k = max(sil_scores, key=sil_scores.get)\n",
    "print('Best K by silhouette:', best_k)\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10).fit(X_scaled)\n",
    "df['kmeans_cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9b51d",
   "metadata": {},
   "source": [
    "## 5) Hierarchical Agglomerative Clustering\n",
    "We'll apply AgglomerativeClustering with the same number of clusters and compare silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hierarchical clustering ---\n",
    "agg = AgglomerativeClustering(n_clusters=best_k, linkage='ward')\n",
    "df['agg_cluster'] = agg.fit_predict(X_scaled)\n",
    "sil_kmeans = silhouette_score(X_scaled, df['kmeans_cluster'])\n",
    "sil_agg = silhouette_score(X_scaled, df['agg_cluster'])\n",
    "print(f'Silhouette KMeans: {sil_kmeans:.4f} | Silhouette Agglomerative: {sil_agg:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5f25d",
   "metadata": {},
   "source": [
    "## 6) Cluster Summary & Profiling\n",
    "- Show cluster sizes and mean feature values per cluster\n",
    "- Visualize cluster distribution via barplots and map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83751f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cluster profiling for KMeans ---\n",
    "profile_k = df.groupby('kmeans_cluster')[cols_for_clustering].mean().T\n",
    "profile_k['overall'] = df[cols_for_clustering].mean()\n",
    "profile_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sizes\n",
    "print('KMeans cluster sizes:')\n",
    "print(df['kmeans_cluster'].value_counts().sort_index())\n",
    "print('\\nAgglomerative cluster sizes:')\n",
    "print(df['agg_cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a25038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot of mean Tot Cases per M by cluster (KMeans)\n",
    "if 'Tot Cases//1M pop' in df.columns:\n",
    "    mean_cases = df.groupby('kmeans_cluster')['Tot Cases//1M pop'].mean().reset_index()\n",
    "    sns.barplot(data=mean_cases, x='kmeans_cluster', y='Tot Cases//1M pop')\n",
    "    plt.title('Mean Tot Cases per M by KMeans cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Mean Cases per M')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map colored by cluster (KMeans)\n",
    "if 'ISO 3166-1 alpha-3 CODE' in df.columns:\n",
    "    fig = px.choropleth(df, locations='ISO 3166-1 alpha-3 CODE', color='kmeans_cluster',\n",
    "                        hover_name='Country', projection='natural earth',\n",
    "                        title='KMeans cluster assignment by country')\n",
    "    fig.show()\n",
    "else:\n",
    "    print('No ISO codes found for map visualization')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f8b24",
   "metadata": {},
   "source": [
    "## 7) Government Policy Recommendations (example templates)\n",
    "For each cluster, provide actionable recommendations. Example templates:\n",
    "- **Cluster 0**: Very high deaths per million and high CFR → *Priority: increase ICU capacity, accelerate vaccination, strengthen surveillance and contact tracing.*  \n",
    "- **Cluster 1**: Low reported cases and low deaths per million but very low testing rate (possible underreporting) → *Priority: increase testing, audit reporting systems.*  \n",
    "- **Cluster 2**: Moderate cases, low CFR → *Priority: maintain vaccination campaign and targeted NPIs to protect vulnerable groups.*\n",
    "\n",
    "**Write targeted suggestions for each cluster based on the profiling table above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c338252",
   "metadata": {},
   "source": [
    "## 8) Model comparison & conclusion\n",
    "- Compare silhouette scores and stability of clusters. Prefer the model with higher silhouette and clearer, interpretable clusters.  \n",
    "- Also consider if hierarchical clustering better preserves geographic/continent structures or if KMeans gives tighter clusters in the scaled feature space.\n",
    "\n",
    "**Conclusion (example):** KMeans achieved a slightly higher silhouette score compared to Agglomerative, and cluster profiling produced clear groups (high-risk, medium-risk, low-risk). Therefore, choose KMeans for this dataset, but mention limitations (reporting biases, single snapshot, missing features such as testing rates or vaccination coverage)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
