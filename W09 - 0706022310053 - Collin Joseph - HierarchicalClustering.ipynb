{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb6c70e",
   "metadata": {},
   "source": [
    "# W09 — Hierarchical Clustering\n",
    "\n",
    "**Notebook template** following the W09 assignment. Replace `NIM` and `Name` in the filename before submission.\n",
    "\n",
    "This notebook includes:\n",
    "- Data loading & preprocessing (Part A)\n",
    "- EDA visualizations (Part B)\n",
    "- Data preparation and silhouette experiments (Part C)\n",
    "- Two hierarchical clustering models + dendrograms (Part D)\n",
    "- Comparison, interpretation, and managerial insights (Part E)\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset:** property_data_clustering_clean.csv\n",
    "\n",
    "**Note:** This notebook is ready to run on your machine or Google Colab (internet access required to download the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A – Data Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/NathaliaMinoque/datasets/refs/heads/main/property_data_clustering_clean.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1) Initial inspection\n",
    "print('Shape:', df.shape)\n",
    "print('\\nInfo:')\n",
    "print(df.info())\n",
    "\n",
    "# 2) Missing / inconsistent values\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isna().sum())\n",
    "\n",
    "# 3) Unique values for categorical columns\n",
    "cat_cols = ['Nama Daerah','Terjual/Belum','Arah Hadap Rumah','Posisi Rumah','Lebar Jalan Depan Rumah (ROW)']\n",
    "for c in cat_cols:\n",
    "    if c in df.columns:\n",
    "        print(f'\\nUnique values in {c}:')\n",
    "        print(df[c].value_counts(dropna=False))\n",
    "\n",
    "# Show head\n",
    "print('\\nFirst 5 rows:')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ef5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B – Exploratory Data Analysis (2 visualizations)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure numeric cols are correct\n",
    "num_cols = ['Luas Tanah (m2)','Luas Bangunan (m2)','Jumlah Kamar','Jumlah Kamar Mandi','Tingkat/Lantai','Harga Penawaran (dari Owner)']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Viz 1: Correlation heatmap (using matplotlib only)\n",
    "corr = df[num_cols].corr()\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.title('Correlation matrix (numeric features)')\n",
    "plt.xticks(range(len(num_cols)), num_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(num_cols)), num_cols)\n",
    "for (i, j), val in np.ndenumerate(corr.values):\n",
    "    plt.text(j, i, f\"{val:.2f}\", ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Viz 2: Boxplot of Harga Penawaran by Terjual/Belum (if present)\n",
    "if 'Terjual/Belum' in df.columns:\n",
    "    groups = df[['Terjual/Belum','Harga Penawaran (dari Owner)']].dropna()\n",
    "    labels = groups['Terjual/Belum'].unique().tolist()\n",
    "    data = [groups.loc[groups['Terjual/Belum']==lab,'Harga Penawaran (dari Owner)'].values for lab in labels]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.boxplot(data)\n",
    "    plt.xticks(range(1,len(labels)+1), labels)\n",
    "    plt.ylabel('Harga Penawaran (IDR)')\n",
    "    plt.title('Harga Penawaran by Terjual/Belum')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Column Terjual/Belum not found — skipping second plot.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d68d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C – Data Preparation for Clustering\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "# Select features to use for clustering (numerical + encoded categorical)\n",
    "num_features = ['Luas Tanah (m2)','Luas Bangunan (m2)','Jumlah Kamar','Jumlah Kamar Mandi','Tingkat/Lantai','Harga Penawaran (dari Owner)']\n",
    "cat_features = [c for c in ['Nama Daerah','Arah Hadap Rumah','Posisi Rumah','Lebar Jalan Depan Rumah (ROW)','Terjual/Belum'] if c in df.columns]\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), [c for c in num_features if c in df.columns]),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ], remainder='drop')\n",
    "\n",
    "X = preprocessor.fit_transform(df)\n",
    "print('Processed feature matrix shape:', X.shape)\n",
    "\n",
    "# Experiment with parameters and record silhouette scores\n",
    "linkages = ['complete','average','single','ward']\n",
    "dist_metrics = ['euclidean','manhattan']\n",
    "cluster_range = [2,3,4,5]\n",
    "\n",
    "results = []\n",
    "for n_clusters, link, metric in product(cluster_range, linkages, dist_metrics):\n",
    "    if link == 'ward' and metric != 'euclidean':\n",
    "        continue\n",
    "    try:\n",
    "        model = AgglomerativeClustering(n_clusters=n_clusters, linkage=link, affinity=metric)\n",
    "        labels = model.fit_predict(X)\n",
    "        sil = silhouette_score(X, labels, metric=metric)\n",
    "        results.append({'n_clusters':n_clusters,'linkage':link,'metric':metric,'silhouette':sil})\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values('silhouette', ascending=False)\n",
    "print('\\nTop silhouette results:')\n",
    "print(res_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part D – Hierarchical Clustering Modeling\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Choose best params from res_df\n",
    "best = res_df.iloc[0] if not res_df.empty else None\n",
    "if best is not None:\n",
    "    best_n = int(best['n_clusters'])\n",
    "    best_link = best['linkage']\n",
    "    best_metric = best['metric']\n",
    "else:\n",
    "    best_n, best_link, best_metric = 3, 'average', 'euclidean'\n",
    "\n",
    "# Model 1 dendrogram\n",
    "Z1 = linkage(X, method=best_link, metric=best_metric)\n",
    "plt.figure(figsize=(12,4))\n",
    "dendrogram(Z1, truncate_mode='level', p=5)\n",
    "plt.title(f'Dendrogram — Model 1 ({best_link} - {best_metric})')\n",
    "plt.show()\n",
    "\n",
    "# Model 2 (Ward)\n",
    "Z2 = linkage(X, method='ward')\n",
    "plt.figure(figsize=(12,4))\n",
    "dendrogram(Z2, truncate_mode='level', p=5)\n",
    "plt.title('Dendrogram — Model 2 (ward)')\n",
    "plt.show()\n",
    "\n",
    "# Fit Agglomerative models\n",
    "model1 = AgglomerativeClustering(n_clusters=best_n, linkage=best_link, affinity=best_metric)\n",
    "labels1 = model1.fit_predict(X)\n",
    "model2 = AgglomerativeClustering(n_clusters=best_n, linkage='ward', affinity='euclidean')\n",
    "labels2 = model2.fit_predict(X)\n",
    "\n",
    "# Merge labels\n",
    "\n",
    "df['cluster_model1'] = labels1\n",
    "df['cluster_model2'] = labels2\n",
    "print(df[['cluster_model1','cluster_model2']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part E – Comparison & Interpretation\n",
    "numeric = [c for c in num_features if c in df.columns]\n",
    "\n",
    "print('Model 1 cluster means:')\n",
    "print(df.groupby('cluster_model1')[numeric].mean())\n",
    "\n",
    "print('\\nModel 2 cluster means:')\n",
    "print(df.groupby('cluster_model2')[numeric].mean())\n",
    "\n",
    "# Managerial insights\n",
    "print('\\nManagerial insights (example):')\n",
    "print('- Use high-price cluster characteristics to craft premium listings and marketing.')\n",
    "print('- Identify underperforming areas (low sale rate) to run promotions or adjust pricing.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb76e4de",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "- Save this notebook as `W09 - NIM - Name.ipynb` (replace with your NIM and Name).\n",
    "- Push to GitHub and submit the repository link as requested by the assignment.\n",
    "\n",
    "---\n",
    "*Notebook generated automatically. Review & adapt the analysis, interpretations, and plots before final submission.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
